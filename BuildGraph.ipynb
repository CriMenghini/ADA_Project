{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from BuildGraphModule import *\n",
    "from unidecode import unidecode\n",
    "from graviz import graph_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('paper.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uniform strings - Authors\n",
    "for i in list(data.keys()):\n",
    "    try:\n",
    "        for j in range(len(data[i]['Authors'])):\n",
    "            t = unidecode(data[i]['Authors'][j])\n",
    "            t.encode(\"ascii\")\n",
    "            data[i]['Authors'][j] = t.lower().replace('.','')\n",
    "            \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uniform strings - EPFL Authors\n",
    "for i in list(data.keys()):\n",
    "    dic = []\n",
    "    try:\n",
    "        for j in range(len(data[i]['Epfl authors'])):\n",
    "            string = list(data[i]['Epfl authors'][j].keys())[0]\n",
    "            t = unidecode(string)\n",
    "            t.encode(\"ascii\")\n",
    "            dic += [{t.lower().replace('.','') : list(data[i]['Epfl authors'][j].values())[0]}]\n",
    "        data[i]['Epfl authors'] = dic\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = get_authors(data, 'Authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All\n",
    "dictionary_a_id, dictionary_id_a = create_authors_id(authors, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All\n",
    "dict_authors = list_coauthors(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All\n",
    "dict_numb_coll = number_collaborations(dict_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All\n",
    "dict_authors_set = set_coauthors(dict_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All\n",
    "edges = create_edges(dict_authors_set, dictionary_a_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPFL graph: Multiplegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors_epfl = get_authors(data, 'Epfl authors')\n",
    "# Due to the format which the authors have been saved\n",
    "\n",
    "# We initialize a new list\n",
    "epfl_authors = []\n",
    "\n",
    "# Then for each element in the previous list\n",
    "for i in authors_epfl:\n",
    "    # We unpack the content\n",
    "    epfl_authors += list(i.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Id-Author / Author-ID\n",
    "dictionary_a_id_epfl, dictionary_id_a_epfl = create_authors_id(epfl_authors, 'epfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EPFL - COAUTORI NELLA LISTA DI EPFL AUTHORS\n",
    "dict_authors_epfl = list_coauthors_epfl(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of collaborations\n",
    "dict_numb_coll_epfl = number_collaborations(dict_authors_epfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coauthors set\n",
    "dict_authors_set_epfl = set_coauthors(dict_authors_epfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set of edges\n",
    "edges_epfl = create_edges(dict_authors_set_epfl, dictionary_a_id_epfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 13451\n",
      "Number of edges: 45417\n",
      "Average degree:   6.7530\n"
     ]
    }
   ],
   "source": [
    "G = create_simple_graph(dictionary_id_a_epfl, edges_epfl)\n",
    "nx.set_node_attributes(G, 'author_id', dictionary_id_a_epfl)\n",
    "graph_processing.save_graph(G, 'graph.json', 'JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dictionary\n",
    "dict_authors_epfl = defaultdict(list)\n",
    "\n",
    "# For each pubblication\n",
    "for p in list(data.keys()):\n",
    "    # If present\n",
    "    try:\n",
    "        # Extracte the list of epfl authors\n",
    "        list_authors_raw = data[p]['Epfl authors']\n",
    "        # Unpack the list\n",
    "        list_authors_list = [list(i.keys()) for i in list_authors_raw]\n",
    "\n",
    "        # Whether the list of authors contains more than one element\n",
    "        if len(list_authors_list) > 1:\n",
    "            # Get the final list unpacking elements\n",
    "            list_authors = [i[0] for i in list_authors_list]\n",
    "        else:\n",
    "            # Just get the element as the list\n",
    "            list_authors = list_authors_list[0]\n",
    "\n",
    "        # For each author create an instance in the dictionary\n",
    "        for a in list_authors:\n",
    "            dict_authors_epfl[a] += [{j:p} for j in list_authors if j != a]\n",
    "\n",
    "    # If there re not epfl authors continue the loop\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_coautorship_papers = {}\n",
    "for author in list(dict_authors_epfl.keys()):\n",
    "    \n",
    "    dict_papers = defaultdict(list)\n",
    "    for i in range(len(dict_authors_epfl[author])):\n",
    "\n",
    "        coauthor = list(dict_authors_epfl[author][i].keys())[0]\n",
    "\n",
    "        dict_papers[coauthor] += [(dict_authors_epfl[author][i])[coauthor]]\n",
    "\n",
    "    dict_coautorship_papers[author] = dict_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "dictionary_occ = {}\n",
    "for i in list(dict_coautorship_papers.keys()):\n",
    "    dictionary[i] = {}\n",
    "    dictionary_occ[i] = {}\n",
    "    for j in list(dict_coautorship_papers[i].keys()):\n",
    "        dates = defaultdict(list)\n",
    "        for l in range(len(dict_coautorship_papers[i][j])):\n",
    "            try:\n",
    "                dates[data[sorted(dict_coautorship_papers[i][j])[l]]['Publication date']] += [sorted(dict_coautorship_papers[i][j])[l]]\n",
    "            except:\n",
    "                continue\n",
    "        if len(dates) != 0:\n",
    "            dictionary[i][j] = dates\n",
    "            dictionary_occurences = {}\n",
    "            for k,m in dictionary[i][j].items():\n",
    "                dictionary_occurences[k] = len(m)\n",
    "            dictionary_occ[i][j] = dictionary_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an epty set of edges\n",
    "edges = set()\n",
    "\n",
    "# For each author\n",
    "for key in list(dict_authors_set_epfl.keys()):       \n",
    "    # If the list of co-authors is not empty\n",
    "    if len(dict_authors_set_epfl[key]) != 0:\n",
    "        # Create sorted tuples between the author and his coauthors\n",
    "        new_edges = [tuple(sorted((dictionary_a_id_epfl[key], dictionary_a_id_epfl[co]))) for co in dict_authors_set_epfl[key]]\n",
    "\n",
    "        # Update the set in order to not have the double arches\n",
    "        edges.update(new_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary['catasta michele']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary_occ['catasta michele']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_epfl = nx.MultiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_epfl.add_nodes_from(list(dictionary_id_a_epfl.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_epfl.add_edges_from(list(edges_epfl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_edges = []\n",
    "to_remove = []\n",
    "for i,j in list(edges_epfl):\n",
    "    \n",
    "    try:    \n",
    "        for k in list(dictionary_occ[dictionary_id_a_epfl[i]][dictionary_id_a_epfl[j]].keys()):\n",
    "        #print (list(dictionary_occ[dictionary_id_a_epfl[i]][dictionary_id_a_epfl[j]].keys()))\n",
    "        #print (i,j)\n",
    "            new_edges += [(i, j, dict(year = k))]\n",
    "            to_remove += [(i,j)]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_epfl.add_edges_from(new_edges)\n",
    "#G_epfl.remove_edges_from(set(to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary_a_id_epfl['agir berker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,j in G_epfl.edges():\n",
    "    for k in G_epfl[i][j]:\n",
    "        #print (k)\n",
    "        if k == 0:\n",
    "            G_epfl[i][j][k]['weight'] = dict_numb_coll_epfl[dictionary_id_a_epfl[i]][dictionary_id_a_epfl[j]]\n",
    "        else:\n",
    "            #print (G_epfl[i][j][k]['year'])\n",
    "            G_epfl[i][j][k]['weight'] = dictionary_occ[dictionary_id_a_epfl[i]][dictionary_id_a_epfl[j]][G_epfl[i][j][k]['year']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_epfl[dictionary_a_id_epfl['catasta michele']]#[1]#['weight'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G[dictionary_a_id_epfl['catasta michele']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in G.edges():\n",
    "    for k in G[i]:\n",
    "        #print (k)\n",
    "        \n",
    "        G[i][j]['weight'] = dict_numb_coll_epfl[dictionary_id_a_epfl[i]][dictionary_id_a_epfl[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic statistics on the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the range of years\n",
    "dict_years = defaultdict(int)\n",
    "for paper in list(data.keys()):\n",
    "    try:\n",
    "        #print (paper['Publication date'])\n",
    "        dict_years[data[paper]['Publication date']] += 1\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dict_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dict_years['August 31-September 2 2005']\n",
    "del dict_years['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a first glance twe observe that:\n",
    "* The oldest publications are thos which may contain fragmented and incomplete information\n",
    "* The number of publication in considerably higher from the latest 90s to nowdays\n",
    "\n",
    "As consequence we decide to focus our attention on the publications corresponding to the aforementioned period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(dict_years.keys(), dict_years.values(), 0.5, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_cut = {}\n",
    "for paper in list(data.keys()):\n",
    "    try:\n",
    "        if int(data[paper]['Publication date']) >= 1993:\n",
    "            data_cut[paper] = data[paper]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_cut['52256']['Labs involved'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (lab,website)\n",
    "dict_lab_site = {}\n",
    "# (lab, num publications)\n",
    "dict_labs = defaultdict(int)\n",
    "# (lab, list of papers)\n",
    "dict_labs_paper = defaultdict(list)\n",
    "i = 0\n",
    "for paper in list(data_cut.keys()):\n",
    "    try:\n",
    "        if len(data_cut[paper]['Labs involved']) == 1:\n",
    "            dict_lab_site[list(data_cut[paper]['Labs involved'][0].keys())[0]] = list(data_cut[paper]['Labs involved'][0].values())[0]\n",
    "            dict_labs[list(data_cut[paper]['Labs involved'][0].keys())[0]] += 1\n",
    "            dict_labs_paper[list(data_cut[paper]['Labs involved'][0].keys())[0]] += [paper]\n",
    "            \n",
    "        else:\n",
    "            #print ('else')\n",
    "            for lab in data_cut[paper]['Labs involved']:\n",
    "                dict_lab_site[list(lab.keys())[0]] = list(lab.values())[0]     \n",
    "                dict_labs[list(lab.keys())[0]] += 1\n",
    "                dict_labs_paper[list(lab.keys())[0]] += [paper]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPFL STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "req = requests.get('https://search.epfl.ch/ubrowse.action?acro=EPFL')\n",
    "html = req.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(soup.findAll('div', {'class':'unit_name'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_links_to_go = []\n",
    "dictio = []\n",
    "for i in soup.findAll('div', {'class':'unit_name'}):\n",
    "    if i.findAll('a')[0].text.strip()[:6] == 'School':\n",
    "        new_links_to_go += [i.findAll('a')[0].get('href')]\n",
    "        dictio += [i.findAll('a')[0].text.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_links_to_go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prova = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverse_epfl_tree(root):\n",
    "    global prova\n",
    "    \n",
    "    #Request root url\n",
    "    request = requests.get(root)\n",
    "    html = request.content\n",
    "    #get the soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    #find eventual children\n",
    "    children = soup.findAll(\"div\", { \"class\" : \"unit_name\" })\n",
    "    #check if node is a leaf\n",
    "    \n",
    "    is_leaf = (len(children) == 0)\n",
    "    #print (is_leaf)\n",
    "    #parse and add node to the db (see def of create_node)\n",
    "    \n",
    "    #create_node(soup, is_leaf) # save data \n",
    "    \n",
    "    if is_leaf == False:\n",
    "        #continue exploring the tree\n",
    "        for elem in children:\n",
    "            print (soup.findAll('h2')[0].text.replace('\\n',' ').split('  ')[0])\n",
    "            prova[soup.findAll('h2')[0].text.replace('\\n',' ').split('  ')[0]] += [elem.findAll('a')[0].text.strip()]\n",
    "            #print (elem)\n",
    "            traverse_epfl_tree(\"https://search.epfl.ch\" + elem.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#traverse_epfl_tree('https://search.epfl.ch/ubrowse.action?acro=SV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(prova, open('SV.p', 'wb')) # Store the variable in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_SV = pickle.load(open('SV.p', 'rb')) # Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dictionary (lab,school)\n",
    "def school_lab(dict_lab_site, name_school):\n",
    "    \n",
    "    school = pickle.load(open(name_school + '.p', 'rb')) # Recall \n",
    "    lab_school = {}\n",
    "    for i in list(dict_lab_site.keys()):\n",
    "        for nodes in list(school.keys()):\n",
    "            list_node = school[nodes]\n",
    "            if i in list_node:\n",
    "                lab_school[i] = name_school\n",
    "                break\n",
    "            else:\n",
    "                continue   \n",
    "    \n",
    "    return lab_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_lab(dict_lab_site, 'IC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
